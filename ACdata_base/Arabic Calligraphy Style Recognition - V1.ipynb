{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb2c8a2",
   "metadata": {},
   "source": [
    "# Reference Paper\n",
    "## An efficient multiple-classifier system for Arabic calligraphy style recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eb592df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from skimage.morphology import skeletonize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import os\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from __future__ import division\n",
    "from scipy.signal import convolve2d\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99079f56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Reference: https://stackoverflow.com/questions/23548863/converting-a-specific-matlab-script-to-python/23575137\n",
    "def lpq(img,winSize=3,freqestim=1,mode='nh'):\n",
    "    rho=0.90\n",
    "\n",
    "    STFTalpha=1/winSize  # alpha in STFT approaches (for Gaussian derivative alpha=1)\n",
    "    sigmaS=(winSize-1)/4 # Sigma for STFT Gaussian window (applied if freqestim==2)\n",
    "    sigmaA=8/(winSize-1) # Sigma for Gaussian derivative quadrature filters (applied if freqestim==3)\n",
    "\n",
    "    convmode='valid' # Compute descriptor responses only on part that have full neigborhood. Use 'same' if all pixels are included (extrapolates np.image with zeros).\n",
    "\n",
    "    img=np.float64(img) # Convert np.image to double\n",
    "    r=(winSize-1)/2 # Get radius from window size\n",
    "    x=np.arange(-r,r+1)[np.newaxis] # Form spatial coordinates in window\n",
    "\n",
    "    if freqestim==1:  #  STFT uniform window\n",
    "        #  Basic STFT filters\n",
    "        w0=np.ones_like(x)\n",
    "        w1=np.exp(-2*np.pi*x*STFTalpha*1j)\n",
    "        w2=np.conj(w1)\n",
    "\n",
    "    ## Run filters to compute the frequency response in the four points. Store np.real and np.imaginary parts separately\n",
    "    # Run first filter\n",
    "    filterResp1=convolve2d(convolve2d(img,w0.T,convmode),w1,convmode)\n",
    "    filterResp2=convolve2d(convolve2d(img,w1.T,convmode),w0,convmode)\n",
    "    filterResp3=convolve2d(convolve2d(img,w1.T,convmode),w1,convmode)\n",
    "    filterResp4=convolve2d(convolve2d(img,w1.T,convmode),w2,convmode)\n",
    "\n",
    "    # Initilize frequency domain matrix for four frequency coordinates (np.real and np.imaginary parts for each frequency).\n",
    "    freqResp=np.dstack([filterResp1.real, filterResp1.imag,\n",
    "                        filterResp2.real, filterResp2.imag,\n",
    "                        filterResp3.real, filterResp3.imag,\n",
    "                        filterResp4.real, filterResp4.imag])\n",
    "\n",
    "    ## Perform quantization and compute LPQ codewords\n",
    "    inds = np.arange(freqResp.shape[2])[np.newaxis,np.newaxis,:]\n",
    "    LPQdesc=((freqResp>0)*(2**inds)).sum(2)\n",
    "\n",
    "    ## Switch format to uint8 if LPQ code np.image is required as output\n",
    "    if mode=='im':\n",
    "        LPQdesc=np.uint8(LPQdesc)\n",
    "\n",
    "    ## Histogram if needed\n",
    "    if mode=='nh' or mode=='h':\n",
    "        LPQdesc=np.histogram(LPQdesc.flatten(),range(256))[0]\n",
    "\n",
    "    ## Normalize histogram if needed\n",
    "    if mode=='nh':\n",
    "        LPQdesc=LPQdesc/LPQdesc.sum()\n",
    "\n",
    "    #print(LPQdesc)\n",
    "    return LPQdesc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "082bcd1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainData = []\n",
    "trainDataLabels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c3778a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "    ret2,th2 = cv2.threshold(image,0,1,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    return th2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc479da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def extractFeatures(image):\n",
    "    return lpq(image, winSize=5, mode='nh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0bd0af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 diwani\n",
      "2 naskh\n",
      "3 parsi\n",
      "4 rekaa\n",
      "5 thuluth\n",
      "6 maghribi\n",
      "7 kufi\n",
      "8 mohakek\n",
      "9 Squar-kufic\n"
     ]
    }
   ],
   "source": [
    "fontFile = open(\"names.txt\",'r')\n",
    "fonts = np.loadtxt(fontFile, dtype='str')\n",
    "for font in fonts:\n",
    "    fontDir, fontName = font.split(\"___\")\n",
    "    print(fontDir, fontName)\n",
    "    for file in os.listdir(fontDir):\n",
    "        image = cv2.imread(fontDir+\"/\"+file,0)\n",
    "        image_processed = preprocessing(image)\n",
    "        trainData.append(image_processed)\n",
    "        trainDataLabels.append(fontName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d94795cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\hebaa\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "trainData = np.asarray(trainData)\n",
    "trainDataLabels = np.asarray(trainDataLabels)\n",
    "\n",
    "N = trainData.shape[0]\n",
    "trainFeatures = np.zeros((N, 255))\n",
    "\n",
    "for i in range(trainFeatures.shape[0]):\n",
    "    trainFeatures[i] = extractFeatures(trainData[i])\n",
    "    \n",
    "#print(trainData.shape, trainDataLabels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50838ba4",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91c1c4a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy KNN: 94.540059347181\n"
     ]
    }
   ],
   "source": [
    "clf_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "clf_knn.fit(trainFeatures, trainDataLabels)\n",
    "y_pred_knn = clf_knn.predict(trainFeatures)\n",
    "print(\"Accuracy KNN:\",metrics.accuracy_score(trainDataLabels, y_pred_knn)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66334ffe",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1460874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM: 56.73590504451038\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(decision_function_shape='ovo',probability=True, kernel='rbf')\n",
    "clf_svm.fit(trainFeatures, trainDataLabels)\n",
    "y_pred_svm = clf_svm.predict(trainFeatures)\n",
    "print(\"Accuracy SVM:\",metrics.accuracy_score(trainDataLabels, y_pred_svm)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60bf135",
   "metadata": {},
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a830479a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy MLPClassifier: 98.57566765578635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\hebaa\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf_mlp = MLPClassifier(random_state=1, max_iter=500)\n",
    "clf_mlp.fit(trainFeatures, trainDataLabels)\n",
    "y_pred_mlp = clf_mlp.predict(trainFeatures)\n",
    "print(\"Accuracy MLPClassifier:\",metrics.accuracy_score(trainDataLabels, y_pred_mlp)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28304d2",
   "metadata": {},
   "source": [
    "## Combining Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f432cf9b",
   "metadata": {},
   "source": [
    "###  Majority/Plurality Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1844a198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\hebaa\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - Majority Vote: 91.98813056379822\n"
     ]
    }
   ],
   "source": [
    "clf_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "clf_mlp = MLPClassifier(random_state=1, max_iter=500)\n",
    "clf_svm = svm.SVC(decision_function_shape='ovo',probability=True)\n",
    "\n",
    "\n",
    "clf_max = VotingClassifier(estimators=[('knn', clf_knn), ('svm', clf_svm), ('mlp', clf_mlp)], voting='hard')\n",
    "clf_max.fit(trainFeatures, trainDataLabels)\n",
    "y_pred_max = clf_max.predict(trainFeatures)\n",
    "\n",
    "print(\"Accuracy - Majority Vote:\",metrics.accuracy_score(trainDataLabels, y_pred_max)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9938fb73",
   "metadata": {},
   "source": [
    "###  Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e58c954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\hebaa\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - Sum: 95.78635014836794\n"
     ]
    }
   ],
   "source": [
    "clf_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "clf_mlp = MLPClassifier(random_state=1, max_iter=500)\n",
    "clf_svm = svm.SVC(decision_function_shape='ovo',probability=True)\n",
    "\n",
    "\n",
    "clf_max = VotingClassifier(estimators=[('knn', clf_knn), ('svm', clf_svm), ('mlp', clf_mlp)], voting='soft')\n",
    "clf_max.fit(trainFeatures, trainDataLabels)\n",
    "y_pred_max = clf_max.predict(trainFeatures)\n",
    "\n",
    "print(\"Accuracy - Sum:\",metrics.accuracy_score(trainDataLabels, y_pred_max)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
